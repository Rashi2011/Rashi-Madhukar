{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_basic_Practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPC2hFGQEIpT/hIm9jvnlTw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rashi2011/Rashi-Madhukar/blob/master/NLP_basic_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6odYssh-BeiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKfWnAKqBjJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b8ad676-a3ec-427e-98ca-03af0f85d98a"
      },
      "source": [
        "#Input Text\n",
        "input_txt = \"I am Learning NLP.\"\n",
        "\n",
        "#Convert data into lower case\n",
        "input_txt = input_txt.lower()\n",
        "print(input_txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i am learning nlp.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAblWzRaHVMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d7e7011-4d2a-46f1-968b-7e387827d413"
      },
      "source": [
        "#Tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "data_t = word_tokenize(input_txt)\n",
        "print(data_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'am', 'learning', 'nlp', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OqB2cxKCAxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8de5834-fffb-4b26-bd63-f7ddb3223425"
      },
      "source": [
        "#remove Punctuation\n",
        "import string\n",
        "print(string.punctuation)\n",
        "\n",
        "def remove_punc(txt):\n",
        "  x = [c for c in txt if c not in string.punctuation]\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcZSlKMpETRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "caf7730a-a884-440b-fda2-72d024b236ee"
      },
      "source": [
        "data_tp = remove_punc(data_t)\n",
        "print(data_tp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'am', 'learning', 'nlp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fm7k00ADt_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a444e779-3d8c-4509-ed32-054efe30ca80"
      },
      "source": [
        "#Removing stop words\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "print(stopwords[0:10])\n",
        "\n",
        "def stop_word(txt):\n",
        "  x = [word for word in txt if word  not in stopwords]\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBeYa0vOF3t1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e84a34d-429e-4ec2-dc9a-58063fe9b3f9"
      },
      "source": [
        "data_tps = stop_word(data_tp)\n",
        "print(data_tps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['learning', 'nlp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GcnjUKiGb6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59a72c5d-eb0c-43e7-b5a3-809b835687ce"
      },
      "source": [
        "#WordNet lemmatization\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "print(wn.lemmatize('geese'))\n",
        "\n",
        "def lemmatization(txt):\n",
        "  x = [wn.lemmatize(word) for word in txt]\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "goose\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfcK8h2pJG-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eda46960-aeda-4c04-8987-c4e4a837dd51"
      },
      "source": [
        "data_tpsl = lemmatization(data_tps)\n",
        "data_tpsl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['learning', 'nlp']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Y7YqUzJKky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Porter Stemming\n",
        "from nltk.stem import  PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def porter_stem(txt):\n",
        "  x = [ps.stem(word) for word in txt]\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW0Dfmo6JMMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5815fb7e-8507-4bea-e8aa-a24dd02c1e89"
      },
      "source": [
        "data_tpsls = porter_stem(data_tpsl)\n",
        "data_tpsls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['learn', 'nlp']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsZ4V1h5JPDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "7f817efe-e574-48eb-f59f-32c0b8cabefc"
      },
      "source": [
        "#Vectorization of txt\n",
        "#1. Count Vectorization\n",
        "#2. TFidVectorizer\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#corpus = [\"This is a senetence is\",\"this is another one\",\"this is new sentence\"]\n",
        "corpus = data_tpsls\n",
        "#cv = CountVectorizer()\n",
        "cv = TfidfVectorizer()\n",
        "X = cv.fit(corpus)\n",
        "print(\"Vocabulary\" ,X.vocabulary_)\n",
        "print(cv.get_feature_names())\n",
        "\n",
        "X = cv.transform(corpus)\n",
        "print(\"Shape of X\",X.shape)\n",
        "print(X.toarray())\n",
        "#df = pd.DataFrame(X.toarray,columns = cv.get_feature_names())\n",
        "#print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary {'learn': 0, 'nlp': 1}\n",
            "['learn', 'nlp']\n",
            "Shape of X (2, 2)\n",
            "[[1. 0.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hHofpDFJacF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}